# -*- coding: utf-8 -*-
"""002_LINKEDIN - SOCIAL_MEDIA_PARAMETROS - Nivel Pyspark

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EunkrtzvQD2AGaTleXVudzmj8BXrF4ja
"""

#crtl f9 inicializar tudo

"""#Importações

***Bibliotecas e instalações***
"""

pip install pyspark

pip install fsspec

pip install gcsfs

"""Importando funcções padrão. Função Window também importada porque será usado mais na frente"""

import os
from google.cloud import storage

from pyspark.sql import SparkSession, Window
spark = SparkSession.builder.appName('GCSFilesRead').getOrCreate()

import pyspark.sql.functions as F
from pyspark.sql.functions import to_timestamp, to_date

from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType,BooleanType,DateType,TimestampType
import pandas as pd

"""# Criando Esquema e Dataframe"""

customSchema = StructType([
   StructField("tempo_cargo_anterior", DoubleType(),True),
   StructField("id_usuario", IntegerType(),True),
   StructField("promocoes", IntegerType(),True),
   StructField("dias_cargo_anterior", IntegerType(),True),
   StructField("idade", IntegerType(),True),
   StructField("desfoque", DoubleType(),True),
   StructField("raiva", DoubleType(),True),
   StructField("desgosto", DoubleType(),True),
   StructField("medo", DoubleType(),True),
   StructField("felicidade", DoubleType(),True),
   StructField("neutro", DoubleType(),True),
   StructField("triste", DoubleType(),True),
   StructField("surpresa", DoubleType(),True),
   StructField("etnia", StringType(),True),
   StructField("genero", StringType(),True),
   StructField("oculos", StringType(),True),
   StructField("sorriso", DoubleType(),True),
   StructField("nacionalidade", StringType(),True),
   StructField("seguidores", IntegerType(),True),
   StructField("qualidade_imagem", DoubleType(),True)

])

schema = customSchema

dfspark = pd.read_csv('gs://projetofinalgrupo8/saida/linkedin_tratado_pandas.csv', sep=',', header=0)
df= spark.createDataFrame(dfspark,schema=schema)

df.show(20)

"""#Arredondando os valores das colunas necessárias

"""

df = (df.withColumn("tempo_cargo_anterior",F.round(F.col("tempo_cargo_anterior"),2))
        .withColumn("desfoque",F.round(F.col("desfoque"),2))
        .withColumn("raiva",F.round(F.col("raiva"),2))
        .withColumn("felicidade",F.round(F.col("felicidade"),2))
        .withColumn("neutro",F.round(F.col("neutro"),2))
        .withColumn("triste",F.round(F.col("triste"),2))
        .withColumn("surpresa",F.round(F.col("surpresa"),2))
        .withColumn("sorriso",F.round(F.col("sorriso"),2))
        .withColumn("qualidade_imagem",F.round(F.col("qualidade_imagem"),2))      
)

df.show(5)

"""#Utilizando o comando 'GroupBy'"""

df.groupBy("id_usuario").avg("tempo_cargo_anterior").show(10,truncate=False)

"""***Agrupando a coluna "nacionalidade" e utilizando Aggregate para fazer pesquisas***"""

(df.groupBy(F.col("nacionalidade")).agg(
            F.round(F.mean("promocoes"), 2).alias("media_promocoes"),
            F.round(F.max("promocoes"), 2).alias("max_promocoes"),
            F.round(F.mean("idade"), 2).alias("media_idade"),
            F.round(F.min("idade"), 2).alias("min_idade"),
            F.max("idade").alias("max_idade")
            ).orderBy("max_promocoes")
            .show())

"""
***Agrupando a coluna "idade" e utilizando Aggregate para fazer pesquisas***"""

(df.groupBy(F.col("idade")).agg(
            F.round(F.max("qualidade_imagem"), 2).alias("max_qualidade"),
            F.round(F.mean("qualidade_imagem"), 2).alias("media_qualidade"),
            F.round(F.min("qualidade_imagem"), 2).alias("min_qualidade")
            ).orderBy("media_qualidade").show(20))

(df.groupBy(F.col("idade")).agg(
            F.count("idade").alias("quantidade"),
            F.round(F.max("sorriso"), 2).alias("max_sorriso"),
            F.round(F.mean("sorriso"), 2).alias("media_sorriso"),
            F.round(F.min("sorriso"), 2).alias("min_sorriso")
            ).orderBy("idade").show(20))

"""
Agrupando a coluna "genero" e utilizando Aggregate para fazer pesquisas"""

(df.groupBy(F.col("genero")).agg(
            F.round(F.mean("promocoes"), 2).alias("media_promocoes"),
            F.round(F.max("promocoes"), 2).alias("max_promocoes"),
            F.round(F.mean("idade"), 2).alias("media_idade"),
            F.round(F.min("idade"), 2).alias("min_idade"),
            F.max("idade").alias("maior_idade")
            ).orderBy("max_promocoes").show())

"""#Utilizando o comando 'Window'

***Odernando por idade e selecionando apenas algumas colunas***
"""

w0 = Window.partitionBy(F.col("idade")).orderBy("idade")

(df.withColumn("Rank",F.rank().over(w0))
  .withColumn("idade",F.max(F.col("idade")).over(w0))
  .select("id_usuario","genero","idade","nacionalidade","dias_cargo_anterior")
  .filter(F.col("dias_cargo_anterior") >1).show(10)
)

"""***Odernando por "nacionalidade" e selecionando apenas algumas colunas***"""

w0 = Window.partitionBy(F.col("nacionalidade")).orderBy("idade")

(df.withColumn("Rank",F.rank().over(w0))
  .withColumn("idade",F.max(F.col("idade")).over(w0))
  .select("id_usuario","genero","idade","nacionalidade","dias_cargo_anterior","sorriso","oculos")
  .filter(F.col("idade") >20).show(50)
)

"""#Salvando no bucket"""

serviceAccount = '/content/projetofinalgrupo8-2dcd866c3f46.json'
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = serviceAccount

client = storage.Client()
bucket = client.get_bucket('projetofinalgrupo8')

bucket.blob('saida/linkedin_tratado_pyspark.csv').upload_from_string(df.toPandas().to_csv(index=False), 'text/csv')